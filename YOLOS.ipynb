{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q pytorch-lightning\n",
    "!pip install -q wandb\n",
    "!pip install -q roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"4UnrVt48OCC5jIqxFKgz\")\n",
    "project = rf.workspace(\"roboflow-100\").project(\"cloud-types\")\n",
    "dataset = project.version(2).download(\"coco\")\n",
    "#Register dataset as torchvision CocoDetection\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, img_folder, feature_extractor, train=True):\n",
    "        ann_file = os.path.join(img_folder, \"_annotations.coco.json\")\n",
    "        super(CocoDetection, self).__init__(img_folder, ann_file)\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read in PIL image and target in COCO format\n",
    "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "        \n",
    "        # preprocess image and target (converting target to DETR format, resizing + normalization of both image and target)\n",
    "        image_id = self.ids[idx]\n",
    "        target = {'image_id': image_id, 'annotations': target}\n",
    "        encoding = self.feature_extractor(images=img, annotations=target, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze() # remove batch dimension\n",
    "        target = encoding[\"labels\"][0] # remove batch dimension\n",
    "\n",
    "        return pixel_values, target\n",
    "\n",
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"hustvl/yolos-small\", size=512, max_size=864)\n",
    "\n",
    "train_dataset = CocoDetection(img_folder=(dataset.location + '/train'), feature_extractor=feature_extractor)\n",
    "val_dataset = CocoDetection(img_folder=(dataset.location + '/valid'), feature_extractor=feature_extractor, train=False)\n",
    "\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(val_dataset))\n",
    "self.model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\"\n",
    "model = YoloS(lr=2.5e-5, weight_decay=1e-4)\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "trainer = Trainer(gpus=1, max_epochs=25, gradient_clip_val=0.1, accumulate_grad_batches=12, logger=wandb_logger)\n",
    "trainer.fit(model)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
